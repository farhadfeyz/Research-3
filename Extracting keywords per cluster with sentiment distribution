import pandas as pd
from collections import defaultdict
import ast

# Load data
df = pd.read_csv("clustered_with_sentiment.csv", encoding="utf-8-sig")
df['tokens'] = df['tokens'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

# Structure: {cluster: {word: {'total': X, 'Positive': Y, 'Negative': Z, 'Neutral': W}}}
cluster_word_stats = defaultdict(lambda: defaultdict(lambda: {'total': 0, 'Positive': 0, 'Negative': 0, 'Neutral': 0}))

# Count frequencies with sentiment breakdown
for _, row in df.iterrows():
    cluster = row['cluster']
    sentiment = row['Sentiment_Label']
    for word in row['tokens']:
        cluster_word_stats[cluster][word]['total'] += 1
        cluster_word_stats[cluster][word][sentiment] += 1

# Get top words per cluster with length filtering
results = []
min_length = 4  # Minimum character length requirement

for cluster, words in cluster_word_stats.items():
    # Sort all words by frequency (descending)
    sorted_words = sorted(words.items(), key=lambda x: x[1]['total'], reverse=True)
    
    # Initialize
    top_words = []
    remaining_words = sorted_words.copy()
    
    # Keep selecting until we get 10 valid words
    while len(top_words) < 10 and remaining_words:
        word, counts = remaining_words.pop(0)
        
        # Check word length
        if len(word) >= min_length:
            top_words.append((word, counts))
        # Else: skip this word (implicitly replaced by next in frequency order)
    
    # Handle case where we can't find 10 words meeting criteria
    if len(top_words) < 10:
        print(f"⚠️ Cluster {cluster}: Only found {len(top_words)} words with ≥{min_length} letters")
    
    # Add to results
    for word, counts in top_words:
        results.append({
            'Cluster': cluster,
            'Keyword': word,
            'Length': len(word),  # For verification
            'Total_Frequency': counts['total'],
            'Positive_Count': counts.get('Positive', 0),
            'Negative_Count': counts.get('Negative', 0),
            'Neutral_Count': counts.get('Neutral', 0)
        })

# Create DataFrame
result_df = pd.DataFrame(results)

# Sort by cluster and frequency
result_df = result_df.sort_values(['Cluster', 'Total_Frequency'], ascending=[True, False])

# Save to CSV
result_df.to_csv("top10_keywords_filtered.csv", index=False, encoding="utf-8-sig")

print("✅ Top 10 keywords per cluster (≥4 letters) with sentiment distribution:")
print(result_df.head(20))
